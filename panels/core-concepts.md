# What do we teach in NLP courses?

When we design NLP courses in different contexts, many of us struggle with at least some of the following points.   

- What models, tasks, topics, applications should we include or exclude from the course? For example, 
    - How much time should we spend on hidden Markov models?  
    - Should we include automatic speech recognition in the course? 
    - Is it OK to skip semantic parsing and syntactic parsing? 
- How do we balance theory vs practice? How much detail is appropriate in the given context? For example, 
    - Do we go into the math of Latent Dirichlet Allocation model for topic modeling? 
    - Or is it more useful to spend more time on different practical aspects such as hyperparameters of the model or evaluation and interpretation of the topics given by the model? 
    - How much in detail we should discuss the architecture of LSTMs, given that they're likely to use transformer-based architectures in real life? 
    - Is it a good idea to this time better used if we show them how to train an LSTM for text classification using tools such as `PyTorch` and `TorchText`?
- How do we imbibe _responsible_ and _ethical_ use of NLP?  

## Panelists
|               |                               |
| :---------------- | :------------------------------   | 
| <img src="../img/isabelle.png" alt="Isabella" class="bg-primary" width="250px"> | [**Isabelle Augenstein**](https://isabelleaugenstein.github.io/) is an associate professor in Computer Science at the University of Copenhagen. Her main research interests are fact checking, low-resource learning and explainability. She has developed and taught NLP courses at University of Copenhagen and University College London. She has also given tutorial and talks at a number of summer schools. | 
|<img src="../img/emily.jpeg" alt="Emily" class="bg-primary" width="250px"/> | [**Emily M. Bender**](https://faculty.washington.edu/ebender/index.html) is a Professor of Linguistics and an Adjunct Professor in Computer Science and Engineering at the University of Washington. She is the Director of the [Computational Linguistics Master's program](https://www.compling.uw.edu/). She has a wealth of teaching and mentoring experience, and has taught many courses and seminars in Linguistics, Computational Linguistics, and Ethics in NLP in the past two decades.|
|<img src="../img/yoav.jpeg" alt="Yoav" class="bg-primary" width="250px"> | [**Yoav Goldberg**](https://www.cs.bgu.ac.il/~yoavg/uni/) is a Senior Lecturer in Computer Science at Bar Ilan University. He has taught a number of courses and seminars related NLP. He is the author of the famous tutorial on deep learning NLP, [A Primer on Neural Network Models for Natural Language Processing](https://u.cs.biu.ac.il/~yogo/nnlp.pdf), which has made deep learning NLP accessible to many people.|
| <img src="../img/dan.jpg" alt="Dan" class="bg-primary" width="220px"/> | [**Dan Jurafsky**](https://web.stanford.edu/~jurafsky/) is Professor of Linguistics and Professor of Computer Science at Stanford University. He is a co-author of one of the best books in NLP, [Speech and Language Processing](https://web.stanford.edu/~jurafsky/slp3/), which has taught NLP to many people in the world.|

